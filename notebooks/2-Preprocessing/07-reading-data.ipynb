{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read data files?\n",
    "This notebook describes or points to modules for reading data in different file formats and from different sources.       \n",
    "The $^\\star$ symbol denotes functions or tools available in `DIVAnd.jl`.\n",
    "\n",
    "| Format        | Tool           | \n",
    "| ------------- |:-------------:| \n",
    "| Delimiter-separated values | [readdlm](https://docs.julialang.org/en/stable/stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Type,Char}), [CSV](https://juliadata.github.io/CSV.jl/stable/)\n",
    "| NetCDF        | [NCDatasets.jl](https://github.com/Alexander-Barth/NCDatasets.jl) | \n",
    "| ODV  $^\\star$ | [ODVspreadsheet.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/ODVspreadsheet.jl) |\n",
    "| ODV netCDF $^\\star$   | [NCODV.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/NCODV.jl) | \n",
    "| GEBCO bathymetry $^\\star$ | [load_bath.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_bath.jl)|\n",
    "| Big files $^\\star$    | [loadbigfile](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_obs.jl) |\n",
    "| NetCDF WOD $^\\star$   | [loadobs](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_obs.jl)\n",
    "| Mat files     | [MAT.jl](https://github.com/JuliaIO/MAT.jl)| \n",
    "| GRIB          | [GRIB.jl](https://github.com/weech/GRIB.jl)|\n",
    "| GeoJSON       | [GeoJSON.jl](https://github.com/JuliaGeo/GeoJSON.jl)|\n",
    "| GeoTIFF       | [GeoArrays.jl](https://github.com/evetion/GeoArrays.jl)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://github.com/weech/GRIB.jl/raw/master/test/samples/regular_latlon_surface.grib2\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DIVAnd\n",
    "using DelimitedFiles\n",
    "using CSV\n",
    "include(\"../config.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimiter-separated values files \n",
    "This include the comma-separated values (CSV), the tab-separated values, among others.    \n",
    "We show an example with the NAO indices that we obtain from the [Climate Data Guide](https://climatedataguide.ucar.edu/) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../data/nao_station_annual.txt\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_check(naodatafile, naodatafileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the function without option, the number of columns is deduced from the header, which lead to empty data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155×5 Matrix{Any}:\n",
       "     \"Hurrell\"    \"Station-Based\"  \"Annual\"  \"NAO\"  \"Index\"\n",
       " 1865           -0.66              \"\"        \"\"     \"\"\n",
       " 1866           -0.2               \"\"        \"\"     \"\"\n",
       " 1867           -3.04              \"\"        \"\"     \"\"\n",
       " 1868            4.14              \"\"        \"\"     \"\"\n",
       " 1869            0.42              \"\"        \"\"     \"\"\n",
       " 1870           -2.77              \"\"        \"\"     \"\"\n",
       " 1871           -0.85              \"\"        \"\"     \"\"\n",
       " 1872           -0.83              \"\"        \"\"     \"\"\n",
       " 1873            0.17              \"\"        \"\"     \"\"\n",
       " 1874            2.32              \"\"        \"\"     \"\"\n",
       " 1875           -2.1               \"\"        \"\"     \"\"\n",
       " 1876           -1.85              \"\"        \"\"     \"\"\n",
       "    ⋮                                               \n",
       " 2007            1.35              \"\"        \"\"     \"\"\n",
       " 2008            1.72              \"\"        \"\"     \"\"\n",
       " 2009            0.72              \"\"        \"\"     \"\"\n",
       " 2010           -5.96              \"\"        \"\"     \"\"\n",
       " 2011            2.95              \"\"        \"\"     \"\"\n",
       " 2012           -0.25              \"\"        \"\"     \"\"\n",
       " 2013            0.9               \"\"        \"\"     \"\"\n",
       " 2014            2.97              \"\"        \"\"     \"\"\n",
       " 2015            4.09              \"\"        \"\"     \"\"\n",
       " 2016            1.7               \"\"        \"\"     \"\"\n",
       " 2017            1.14              \"\"        \"\"     \"\"\n",
       " 2018            2.83              \"\"        \"\"     \"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNAO = DelimitedFiles.readdlm(naodatafile, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we indicate that the first line is the header using the option *skipstart*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154×2 Matrix{Float64}:\n",
       " 1865.0  -0.66\n",
       " 1866.0  -0.2\n",
       " 1867.0  -3.04\n",
       " 1868.0   4.14\n",
       " 1869.0   0.42\n",
       " 1870.0  -2.77\n",
       " 1871.0  -0.85\n",
       " 1872.0  -0.83\n",
       " 1873.0   0.17\n",
       " 1874.0   2.32\n",
       " 1875.0  -2.1\n",
       " 1876.0  -1.85\n",
       " 1877.0  -0.24\n",
       "    ⋮    \n",
       " 2007.0   1.35\n",
       " 2008.0   1.72\n",
       " 2009.0   0.72\n",
       " 2010.0  -5.96\n",
       " 2011.0   2.95\n",
       " 2012.0  -0.25\n",
       " 2013.0   0.9\n",
       " 2014.0   2.97\n",
       " 2015.0   4.09\n",
       " 2016.0   1.7\n",
       " 2017.0   1.14\n",
       " 2018.0   2.83"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNAO = DelimitedFiles.readdlm(naodatafile, skipstart=1);\n",
    "dataNAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** if you have a process files in which the decimal separators is comma instead of dots, specific options are available in the module [`CSV`](https://juliadata.github.io/CSV.jl/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetCDF\n",
    "\n",
    "The 2 main modules available for the reading and writing if netCDF files are:\n",
    "1. [NetCDF.jl](https://github.com/JuliaGeo/NetCDF.jl)\n",
    "2. [NCDatasets.jl](https://github.com/Alexander-Barth/NCDatasets.jl)\n",
    "\n",
    "For this workshop we will mainly use `NCDatasets.jl`, described in this [notebook](../1-Intro/03-netCDF.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Bathymetry\n",
    "The General Bathymetric Chart of the Oceans [GEBCO](https://www.gebco.net/) (in netCDF) is directly read with `DIVAnd` using the function `load_bath`.  \n",
    "\n",
    "First make sure we have a bathymetry file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "bathname = gebco16file\n",
    "download_check(gebco16file, gebco16fileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to define the grid on which we need the bathymetry and apply the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonr = -10:0.5:36.\n",
    "latr = 37:0.5:48\n",
    "bx,by,b = load_bath(bathname,true,lonr,latr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "`bx` and `by` are the same as lonr and latr.    \n",
    "`b` contains the bathymetry values.\n",
    "\n",
    "A complete example is provided in the notebook [06-topography.ipynb](./06-topography.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODV spreadsheet\n",
    "ODV spreadsheets constitute one of the standard formats defined in [SeaDataNet](https://www.seadatanet.org/).        \n",
    "In `DIVAnd`, we provide:\n",
    "* [ODVspreadsheet.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/ODVspreadsheet.jl) designed to read such format and\n",
    "* [NCODV.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/NCODV.jl) to read the ODV netCDF files.\n",
    "\n",
    "An example is provided in this the notebook [09-ODV-data-import.ipynb](./09-ODV-data-import.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big files\n",
    "The so-called big files are intermediate files using by DIVA and DIVAnd. The format is rather simple: a tab-separated file containing the following variables:\n",
    "1. longitude,\n",
    "2. latitude,\n",
    "3. field value (e.g., temperature, salinity, chlorophyll concentration, ...), \n",
    "4. depth,\n",
    "5. time,\n",
    "6. measurement identifier.\n",
    "\n",
    "In the module [load_obs.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_obs.jl), the function `loadbigfile` allows the reading of such file format.    \n",
    "In the next cell we download a *big file* containing salinity measurements (also used in other examples) and read it using `loadbigfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoading data from 'big file' ../data/Salinity.bigfile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(obsval) = 139230\n"
     ]
    }
   ],
   "source": [
    "fname = salinitybigfile\n",
    "download_check(salinitybigfile, salinitybigfileURL)\n",
    "\n",
    "\n",
    "obsval,obslon,obslat,obsdepth,obstime,obsid = loadbigfile(fname);\n",
    "@show(length(obsval));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Mat files\n",
    "We use the same .mat file as in [04-OI-variational-analysis-introduction](../1-Intro/04-OI-variational-analysis-introduction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "download_check(danfile, danfileURL)\n",
    "mf = matopen(danfile);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a list of the variables stored in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeySet for a Dict{String, Int64} with 3 entries. Keys:\n",
       "  \"f\"\n",
       "  \"Fe\"\n",
       "  \"F\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varnames = names(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and to load one of them, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizeof(var1) = 20000\n"
     ]
    }
   ],
   "source": [
    "var1 = read(mf, \"f\");\n",
    "@show sizeof(var1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're done, don't forget to close the file (especially if we process a large amount of files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRIB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"GRIB\")\n",
    "using GRIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "download_check(gribfile, gribfileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module `GRIB.jl` works only on Linux and Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m496\n"
     ]
    }
   ],
   "source": [
    "if !Sys.iswindows()\n",
    "    GribFile(gribfile) do f\n",
    "       # Get the first message from f\n",
    "       msg = Message(f)\n",
    "       lons, lats, values = data(msg)\n",
    "       @info(length(lons))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON\n",
    "The sample file has been generated and downloaded from https://geojson.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(fc) = GeoJSON.FeatureCollection{2, Float32}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeoJSON.FeatureCollection{2, Float32}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_check(geojsonfile, geojsonfileURL)\n",
    "\n",
    "jsonbytes = read(geojsonfile);\n",
    "fc = GeoJSON.read(jsonbytes)\n",
    "@show typeof(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geoJSON file contains 2 features, each of them consisting of a 2D Polygon, from which we can extract the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{Tuple{Float32, Float32}}:\n",
       " (27.363369, 41.221752)\n",
       " (30.815773, 40.19586)\n",
       " (34.206352, 40.975384)\n",
       " (41.713684, 39.8079)\n",
       " (43.453205, 41.83671)\n",
       " (39.93689, 44.866375)\n",
       " (40.599613, 48.618225)\n",
       " (34.362835, 47.074516)\n",
       " (30.482286, 48.15362)\n",
       " (25.860664, 45.09467)\n",
       " (27.363369, 41.221752)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon1 = fc[1]\n",
    "polygon1.geometry[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://dox.uliege.be/index.php/s/tz9lCANaNIj3iG2/download\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../config.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoTIFF\n",
    "The image was extracted from https://worldview.earthdata.nasa.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GeoArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "download_check(geotifffile, geotifffileURL)\n",
    "\n",
    "geoarray = GeoArrays.read(geotifffile)\n",
    "coordinates = collect(GeoArrays.coords(geoarray))\n",
    "lats = [cc[2] for cc in reverse(coordinates[1,:])]\n",
    "lons = [cc[1] for cc in coordinates[:,1]]\n",
    "img = reverse(geoarray.A[:,:,1]', dims=1);"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
