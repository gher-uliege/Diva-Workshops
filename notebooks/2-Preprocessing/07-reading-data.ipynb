{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read data files?\n",
    "This notebook describes or points to modules for reading data in different file formats and from different sources.       \n",
    "The $^\\star$ symbol denotes functions or tools available in `DIVAnd.jl`.\n",
    "\n",
    "| Format        | Tool           | \n",
    "| ------------- |:-------------:| \n",
    "| Delimiter-separated values | [readdlm](https://docs.julialang.org/en/stable/stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Type,Char}), [CSV](https://juliadata.github.io/CSV.jl/stable/)\n",
    "| NetCDF        | [NCDatasets.jl](https://github.com/Alexander-Barth/NCDatasets.jl) | \n",
    "| ODV  $^\\star$ | [ODVspreadsheet.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/ODVspreadsheet.jl) |\n",
    "| ODV netCDF $^\\star$   | [NCODV.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/NCODV.jl) | \n",
    "| GEBCO bathymetry $^\\star$ | [load_bath.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_bath.jl)|\n",
    "| Big files $^\\star$    | [loadbigfile](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_obs.jl) |\n",
    "| NetCDF WOD $^\\star$   | [loadobs](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_obs.jl)\n",
    "| Mat files     | [MAT.jl](https://github.com/JuliaIO/MAT.jl)| \n",
    "| GRIB          | [GRIB.jl](https://github.com/weech/GRIB.jl)|\n",
    "| GeoJSON       | [GeoJSON.jl](https://github.com/JuliaGeo/GeoJSON.jl)|\n",
    "| GeoTIFF       | [GeoArrays.jl](https://github.com/evetion/GeoArrays.jl)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://dox.uliege.be/index.php/s/h8d3pyqmuea6J9H/download\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DIVAnd\n",
    "using DelimitedFiles\n",
    "using CSV\n",
    "using Pkg\n",
    "include(\"../config.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimiter-separated values files \n",
    "This include the comma-separated values (CSV), the tab-separated values, among others.    \n",
    "We show an example with the NAO indices that we obtain from the [Climate Data Guide](https://climatedataguide.ucar.edu/) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../data/nao_station_annual.txt\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_check(naodatafile, naodatafileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the function without option, the number of columns is deduced from the header, which lead to empty data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155×5 Matrix{Any}:\n",
       "     \"Hurrell\"    \"Station-Based\"  \"Annual\"  \"NAO\"  \"Index\"\n",
       " 1865           -0.66              \"\"        \"\"     \"\"\n",
       " 1866           -0.2               \"\"        \"\"     \"\"\n",
       " 1867           -3.04              \"\"        \"\"     \"\"\n",
       " 1868            4.14              \"\"        \"\"     \"\"\n",
       " 1869            0.42              \"\"        \"\"     \"\"\n",
       " 1870           -2.77              \"\"        \"\"     \"\"\n",
       " 1871           -0.85              \"\"        \"\"     \"\"\n",
       " 1872           -0.83              \"\"        \"\"     \"\"\n",
       " 1873            0.17              \"\"        \"\"     \"\"\n",
       " 1874            2.32              \"\"        \"\"     \"\"\n",
       " 1875           -2.1               \"\"        \"\"     \"\"\n",
       " 1876           -1.85              \"\"        \"\"     \"\"\n",
       "    ⋮                                               \n",
       " 2007            1.35              \"\"        \"\"     \"\"\n",
       " 2008            1.72              \"\"        \"\"     \"\"\n",
       " 2009            0.72              \"\"        \"\"     \"\"\n",
       " 2010           -5.96              \"\"        \"\"     \"\"\n",
       " 2011            2.95              \"\"        \"\"     \"\"\n",
       " 2012           -0.25              \"\"        \"\"     \"\"\n",
       " 2013            0.9               \"\"        \"\"     \"\"\n",
       " 2014            2.97              \"\"        \"\"     \"\"\n",
       " 2015            4.09              \"\"        \"\"     \"\"\n",
       " 2016            1.7               \"\"        \"\"     \"\"\n",
       " 2017            1.14              \"\"        \"\"     \"\"\n",
       " 2018            2.83              \"\"        \"\"     \"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNAO = DelimitedFiles.readdlm(naodatafile, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we indicate that the first line is the header using the option *skipstart*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154×2 Matrix{Float64}:\n",
       " 1865.0  -0.66\n",
       " 1866.0  -0.2\n",
       " 1867.0  -3.04\n",
       " 1868.0   4.14\n",
       " 1869.0   0.42\n",
       " 1870.0  -2.77\n",
       " 1871.0  -0.85\n",
       " 1872.0  -0.83\n",
       " 1873.0   0.17\n",
       " 1874.0   2.32\n",
       " 1875.0  -2.1\n",
       " 1876.0  -1.85\n",
       " 1877.0  -0.24\n",
       "    ⋮    \n",
       " 2007.0   1.35\n",
       " 2008.0   1.72\n",
       " 2009.0   0.72\n",
       " 2010.0  -5.96\n",
       " 2011.0   2.95\n",
       " 2012.0  -0.25\n",
       " 2013.0   0.9\n",
       " 2014.0   2.97\n",
       " 2015.0   4.09\n",
       " 2016.0   1.7\n",
       " 2017.0   1.14\n",
       " 2018.0   2.83"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNAO = DelimitedFiles.readdlm(naodatafile, skipstart=1);\n",
    "dataNAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** if you have a process files in which the decimal separators is comma instead of dots, specific options are available in the module [`CSV`](https://juliadata.github.io/CSV.jl/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetCDF\n",
    "\n",
    "The 2 main modules available for the reading and writing if netCDF files are:\n",
    "1. [NetCDF.jl](https://github.com/JuliaGeo/NetCDF.jl)\n",
    "2. [NCDatasets.jl](https://github.com/Alexander-Barth/NCDatasets.jl)\n",
    "\n",
    "For this workshop we will mainly use `NCDatasets.jl`, described in this [notebook](../1-Intro/03-netCDF.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Bathymetry\n",
    "The General Bathymetric Chart of the Oceans [GEBCO](https://www.gebco.net/) (in netCDF) is directly read with `DIVAnd` using the function `load_bath`.  \n",
    "\n",
    "First make sure we have a bathymetry file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "bathname = gebco16file\n",
    "download_check(gebco16file, gebco16fileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to define the grid on which we need the bathymetry and apply the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonr = -10:0.5:36.\n",
    "latr = 37:0.5:48\n",
    "bx,by,b = load_bath(bathname,true,lonr,latr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "`bx` and `by` are the same as lonr and latr.    \n",
    "`b` contains the bathymetry values.\n",
    "\n",
    "A complete example is provided in the notebook [06-topography.ipynb](./06-topography.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODV spreadsheet\n",
    "ODV spreadsheets constitute one of the standard formats defined in [SeaDataNet](https://www.seadatanet.org/).        \n",
    "In `DIVAnd`, we provide:\n",
    "* [ODVspreadsheet.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/ODVspreadsheet.jl) designed to read such format and\n",
    "* [NCODV.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/NCODV.jl) to read the ODV netCDF files.\n",
    "\n",
    "An example is provided in this the notebook [09-ODV-data-import.ipynb](./09-ODV-data-import.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big files\n",
    "The so-called big files are intermediate files using by DIVA and DIVAnd. The format is rather simple: a tab-separated file containing the following variables:\n",
    "1. longitude,\n",
    "2. latitude,\n",
    "3. field value (e.g., temperature, salinity, chlorophyll concentration, ...), \n",
    "4. depth,\n",
    "5. time,\n",
    "6. measurement identifier.\n",
    "\n",
    "In the module [load_obs.jl](https://github.com/gher-uliege/DIVAnd.jl/blob/master/src/load_obs.jl), the function `loadbigfile` allows the reading of such file format.    \n",
    "In the next cell we download a *big file* containing salinity measurements (also used in other examples) and read it using `loadbigfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoading data from 'big file' ../data/Salinity.bigfile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(obsval) = 139230\n"
     ]
    }
   ],
   "source": [
    "fname = salinitybigfile\n",
    "download_check(salinitybigfile, salinitybigfileURL)\n",
    "\n",
    "\n",
    "obsval,obslon,obslat,obsdepth,obstime,obsid = loadbigfile(fname);\n",
    "@show(length(obsval));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Mat files\n",
    "We use the same .mat file as in [04-OI-variational-analysis-introduction](../1-Intro/04-OI-variational-analysis-introduction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "download_check(danfile, danfileURL)\n",
    "mf = matopen(danfile);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a list of the variables stored in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeySet for a Dict{String, Int64} with 3 entries. Keys:\n",
       "  \"f\"\n",
       "  \"Fe\"\n",
       "  \"F\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varnames = names(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and to load one of them, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizeof(var1) = 20000\n"
     ]
    }
   ],
   "source": [
    "var1 = read(mf, \"f\");\n",
    "@show sizeof(var1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're done, don't forget to close the file (especially if we process a large amount of files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRIB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"GRIB\")\n",
    "using GRIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "download_check(gribfile, gribfileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module `GRIB.jl` works only on Linux and Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m496\n"
     ]
    }
   ],
   "source": [
    "if !Sys.iswindows()\n",
    "    GribFile(gribfile) do f\n",
    "       # Get the first message from f\n",
    "       msg = Message(f)\n",
    "       lons, lats, values = data(msg)\n",
    "       @info(length(lons))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON\n",
    "The sample file has been generated and downloaded from https://geojson.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(fc) = GeoJSON.FeatureCollection{2, Float32}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeoJSON.FeatureCollection{2, Float32}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_check(geojsonfile, geojsonfileURL)\n",
    "\n",
    "jsonbytes = read(geojsonfile);\n",
    "fc = GeoJSON.read(jsonbytes)\n",
    "@show typeof(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geoJSON file contains 2 features, each of them consisting of a 2D Polygon, from which we can extract the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{Tuple{Float32, Float32}}:\n",
       " (27.363369, 41.221752)\n",
       " (30.815773, 40.19586)\n",
       " (34.206352, 40.975384)\n",
       " (41.713684, 39.8079)\n",
       " (43.453205, 41.83671)\n",
       " (39.93689, 44.866375)\n",
       " (40.599613, 48.618225)\n",
       " (34.362835, 47.074516)\n",
       " (30.482286, 48.15362)\n",
       " (25.860664, 45.09467)\n",
       " (27.363369, 41.221752)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon1 = fc[1]\n",
    "polygon1.geometry[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://dox.uliege.be/index.php/s/tz9lCANaNIj3iG2/download\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../config.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoTIFF\n",
    "GeoTIFF allows georeferencing information to be embedded within an image file.        \n",
    "The test image was extracted from https://worldview.earthdata.nasa.gov/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFile already downloaded\n"
     ]
    }
   ],
   "source": [
    "download_check(geotifffile, geotifffileURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present two ways to read those files:\n",
    "1. With [`GeoArrays`](https://www.evetion.nl/GeoArrays.jl/stable/)\n",
    "2. With [`TIFFDatasets`](https://alexander-barth.github.io/TIFFDatasets.jl/stable/).\n",
    "\n",
    "The advantage of the latter is that is works similarly to [`NCDatasets`](https://alexander-barth.github.io/NCDatasets.jl/stable/), used to read the netCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GeoArrays\n",
    "geoarray = GeoArrays.read(geotifffile)\n",
    "coordinates = collect(GeoArrays.coords(geoarray))\n",
    "lats = [cc[2] for cc in coordinates[1,:]]\n",
    "lons = [cc[1] for cc in coordinates[:,1]]\n",
    "img = reverse(geoarray.A[:,:,1]', dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDataset: ../data/Adriatic-2024-09-16T00_00_00Z.tif\u001b[39m\n",
      "Group: /\n",
      "\n",
      "\u001b[31mDimensions\u001b[39m\n",
      "   cols = 998\n",
      "   rows = 684\n",
      "\n",
      "\u001b[31mVariables\u001b[39m\n",
      "\u001b[32m  lon\u001b[39m   (998 × 684)\n",
      "    Datatype:    \u001b[0m\u001b[1mFloat64\u001b[22m (Float64)\n",
      "    Dimensions:  cols × rows\n",
      "    Attributes:\n",
      "     standard_name        = \u001b[36mlongitude\u001b[39m\n",
      "     units                = \u001b[36mdegrees_east\u001b[39m\n",
      "\n",
      "\u001b[32m  lat\u001b[39m   (998 × 684)\n",
      "    Datatype:    \u001b[0m\u001b[1mFloat64\u001b[22m (Float64)\n",
      "    Dimensions:  cols × rows\n",
      "    Attributes:\n",
      "     standard_name        = \u001b[36mlatitude\u001b[39m\n",
      "     units                = \u001b[36mdegrees_north\u001b[39m\n",
      "\n",
      "\u001b[32m  x\u001b[39m   (998)\n",
      "    Datatype:    \u001b[0m\u001b[1mFloat64\u001b[22m (Float64)\n",
      "    Dimensions:  cols\n",
      "    Attributes:\n",
      "     standard_name        = \u001b[36mprojection_x_coordinate\u001b[39m\n",
      "\n",
      "\u001b[32m  y\u001b[39m   (684)\n",
      "    Datatype:    \u001b[0m\u001b[1mFloat64\u001b[22m (Float64)\n",
      "    Dimensions:  rows\n",
      "    Attributes:\n",
      "     standard_name        = \u001b[36mprojection_y_coordinate\u001b[39m\n",
      "\n",
      "\u001b[32m  crs\u001b[39m  \n",
      "    Attributes:\n",
      "     longitude_of_prime_meridian = \u001b[36m0.0\u001b[39m\n",
      "     semi_major_axis      = \u001b[36m6.378137e6\u001b[39m\n",
      "     inverse_flattening   = \u001b[36m298.257223563\u001b[39m\n",
      "     crs_wkt              = \u001b[36mGEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]\u001b[39m\n",
      "     GeoTransform         = \u001b[36m11.626091081871351 0.008794005847953201 0.0 46.1982 0.0 -0.008794005847953201\u001b[39m\n",
      "\n",
      "\u001b[32m  band1\u001b[39m   (998 × 684)\n",
      "    Datatype:    \u001b[0m\u001b[1mUInt8\u001b[22m (UInt8)\n",
      "    Dimensions:  cols × rows\n",
      "    Attributes:\n",
      "     grid_mapping         = \u001b[36mcrs\u001b[39m\n",
      "\n",
      "\u001b[32m  band2\u001b[39m   (998 × 684)\n",
      "    Datatype:    \u001b[0m\u001b[1mUInt8\u001b[22m (UInt8)\n",
      "    Dimensions:  cols × rows\n",
      "    Attributes:\n",
      "     grid_mapping         = \u001b[36mcrs\u001b[39m\n",
      "\n",
      "\u001b[32m  band3\u001b[39m   (998 × 684)\n",
      "    Datatype:    \u001b[0m\u001b[1mUInt8\u001b[22m (UInt8)\n",
      "    Dimensions:  cols × rows\n",
      "    Attributes:\n",
      "     grid_mapping         = \u001b[36mcrs\u001b[39m\n",
      "\n",
      "\u001b[32m  band4\u001b[39m   (998 × 684)\n",
      "    Datatype:    \u001b[0m\u001b[1mUInt8\u001b[22m (UInt8)\n",
      "    Dimensions:  cols × rows\n",
      "    Attributes:\n",
      "     grid_mapping         = \u001b[36mcrs\u001b[39m\n",
      "\n",
      "\u001b[31mGlobal attributes\u001b[39m\n",
      "  Conventions          = \u001b[36mCF-1.8\u001b[39m\n",
      "  TIFFTAG_XRESOLUTION  = \u001b[36m72\u001b[39m\n",
      "  TIFFTAG_YRESOLUTION  = \u001b[36m72\u001b[39m\n",
      "  TIFFTAG_RESOLUTIONUNIT = \u001b[36m2 (pixels/inch)\u001b[39m\n",
      "  AREA_OR_POINT        = \u001b[36mArea\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using TIFFDatasets\n",
    "ds = TIFFDataset(geotifffile)\n",
    "lons2 = ds[\"lon\"][:,1]\n",
    "lats2 = ds[\"lat\"][1,:]\n",
    "img2 = ds[\"band1\"][:,:]\n",
    "close(ds)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
